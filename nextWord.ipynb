{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNqnjabdmkqsOEGgZC7wxS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhmuller/nextWord/blob/main/nextWord.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zj2LmvbVUMwK"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://towardsdatascience.com/next-word-prediction-with-nlp-and-deep-learning-48b9fe0a17bf"
      ],
      "metadata": {
        "id": "WtMzaio_UWZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "URL = 'https://www.gutenberg.org/files/67138/67138-0.txt'\n",
        "response = requests.get(URL)\n",
        "orig_text = response.content"
      ],
      "metadata": {
        "id": "WHlU_BNnWBPv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M = 2440\n",
        "temp_text = str(orig_text[M:])\n",
        "clean_text = re.sub(\"\\\\\\\\r|\\\\\\\\n|\\\\\\\\xbb|\\\\\\\\xef|\\\\\\\\xbf|'b'\", \" \", temp_text)\n",
        "cleaner_text = clean_text.translate(str.maketrans('', '', string.punctuation))"
      ],
      "metadata": {
        "id": "fVO_fHv2WVtF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaner_text)\n",
        "cleaner_text[:200]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "3kqjI-Z1WzDX",
        "outputId": "b4de2696-ef59-48cc-9f00-39d47bdf4656"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bBOOK I                                          CHAPTER                                     1      Robert Cohn was once middleweight boxing champion of Princeton Do not  think that I am very much imp'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " \n",
        "N = len(cleaner_text)\n",
        "cutoff = int(np.floor(0.5*N))\n",
        "train = cleaner_text[:cutoff]\n",
        "test = cleaner_text[cutoff:]\n",
        "test[:100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "R9ZaPJUrZXNt",
        "outputId": "15612631-2af1-4db6-e081-e5c162823d9f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ulls out of the cages one at  a time and they have steers in the corral to receive them and keep the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "def make_Xy(data, ngram_len=1):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts([data])\n",
        "\n",
        "  sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "  print(len(sequence_data))\n",
        "\n",
        "\n",
        "  sequences = []\n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(1, len(sequence_data)-ngram_len-1):\n",
        "      words = sequence_data[i-1:i+ngram_len]\n",
        "      X.append(words[:-1])\n",
        "      y.append(words[-1])\n",
        "\n",
        "  X = np.array(X)\n",
        "  y = np.array(y)\n",
        "\n",
        "  from  tensorflow.keras.utils import to_categorical\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  y = to_categorical(y, num_classes=vocab_size)\n",
        "  return X, y, tokenizer\n",
        "\n",
        "Xtrain, ytrain, TrainTokenizer = make_Xy(train, ngram_len=3)\n",
        "Xtest, ytest TestTokenizer= make_Xy(test, ngram_len=3)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4QeY9FBpid-",
        "outputId": "650d9595-90d7-402c-98b0-508acd19d6e6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "34953\n",
            "35647\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "def get_vocab_size(data):\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts([data])\n",
        "  vocab_size = len(tokenizer.word_index) + 1\n",
        "  return vocab_size\n",
        "\n",
        "train_vocab_size = get_vocab_size(train)\n",
        "model = Sequential()\n",
        "model.add(Embedding(train_vocab_size, 10, input_length=3))\n",
        "model.add(LSTM(1000, return_sequences=True))\n",
        "model.add(LSTM(1000))\n",
        "model.add(Dense(1000, activation=\"relu\"))\n",
        "model.add(Dense(train_vocab_size, activation=\"softmax\"))"
      ],
      "metadata": {
        "id": "kUcGXoP3lQi9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMZZDjRZmmDH",
        "outputId": "d45b05dc-a0a3-4dbc-bffc-613a7e7f3f8d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 3, 10)             43790     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 3, 1000)           4044000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1000)              1001000   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4379)              4383379   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,476,169\n",
            "Trainable params: 17,476,169\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.2, patience=3, min_lr=0.0001, verbose = 1)\n",
        "\n",
        "logdir='logsnextword1'\n",
        "tensorboard_Visualization = TensorBoard(log_dir=logdir)"
      ],
      "metadata": {
        "id": "MZ4CHsS2ln1s"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(lr=0.001))\n",
        "model.fit(Xtrain, ytrain, epochs=20, batch_size=64, callbacks=[reduce_lr, tensorboard_Visualization])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpTLCgbymiPx",
        "outputId": "4f50a90a-8007-42aa-9092-3dc1515d63f9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "547/547 [==============================] - 10s 14ms/step - loss: 3.7468 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "547/547 [==============================] - 7s 14ms/step - loss: 3.4081 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 3.1240 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 2.8336 - lr: 0.0010\n",
            "Epoch 5/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 2.5589 - lr: 0.0010\n",
            "Epoch 6/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 2.3046 - lr: 0.0010\n",
            "Epoch 7/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 2.0541 - lr: 0.0010\n",
            "Epoch 8/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 1.8289 - lr: 0.0010\n",
            "Epoch 9/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 1.6190 - lr: 0.0010\n",
            "Epoch 10/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 1.4180 - lr: 0.0010\n",
            "Epoch 11/20\n",
            "547/547 [==============================] - 7s 14ms/step - loss: 1.2291 - lr: 0.0010\n",
            "Epoch 12/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 1.0734 - lr: 0.0010\n",
            "Epoch 13/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.9365 - lr: 0.0010\n",
            "Epoch 14/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.8324 - lr: 0.0010\n",
            "Epoch 15/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.7326 - lr: 0.0010\n",
            "Epoch 16/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.6708 - lr: 0.0010\n",
            "Epoch 17/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.6138 - lr: 0.0010\n",
            "Epoch 18/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.5717 - lr: 0.0010\n",
            "Epoch 19/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.5358 - lr: 0.0010\n",
            "Epoch 20/20\n",
            "547/547 [==============================] - 8s 14ms/step - loss: 0.5091 - lr: 0.0010\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa6d225b640>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(Xtest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IF2wBj9WNyB9",
        "outputId": "41986374-a0d4-4a4c-89c2-920d88a676c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1114/1114 [==============================] - 5s 4ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.2267427e-14, 9.0178871e-04, 3.0979807e-06, ..., 1.2346641e-27,\n",
              "        5.8442806e-27, 4.8734345e-29],\n",
              "       [3.1251241e-16, 1.5305555e-10, 2.6710185e-07, ..., 8.4482007e-17,\n",
              "        3.6057772e-22, 2.5465825e-09],\n",
              "       [2.0148448e-24, 1.7789696e-09, 5.1117148e-08, ..., 1.2353672e-24,\n",
              "        1.9465960e-35, 5.0695541e-16],\n",
              "       ...,\n",
              "       [0.0000000e+00, 6.8250122e-03, 1.1955472e-05, ..., 0.0000000e+00,\n",
              "        0.0000000e+00, 0.0000000e+00],\n",
              "       [2.0094394e-16, 1.1435744e-07, 1.4351415e-06, ..., 1.0136074e-21,\n",
              "        3.3032684e-28, 3.3638575e-30],\n",
              "       [6.0626807e-13, 9.1553858e-04, 7.6058881e-05, ..., 1.7249037e-24,\n",
              "        9.0680354e-12, 2.5774711e-25]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ytest.shape"
      ],
      "metadata": {
        "id": "aLHkUwAR0H4E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f809805b-e6f8-4336-d0d8-f1e0dc40ec80"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35642, 4275)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gPUB2zGOC22"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}